{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from Foodtimepredictor.constant import CONFIG_FILE_PATH, PARAMS_FILE_PATH, SCHEMA_FILE_PATH\n",
    "from Foodtimepredictor.utils.common import read_yaml, create_directories, save_obj\n",
    "from Foodtimepredictor import logger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transformation Configuration Class\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path  # Path to the dataset (e.g., 'finalTrain.csv')\n",
    "    data_transformation_preprocessing_obj: Path\n",
    "    data_transformation_dir: Path  # Directory to save transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Manager Class\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH, schema_filepath=SCHEMA_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        create_directories([Path(config.root_dir), Path(config.data_transformation_dir)])\n",
    "        return DataTransformationConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            data_path=Path(config.data_path),\n",
    "            data_transformation_preprocessing_obj=Path(config.data_transformation_preprocessing_obj),\n",
    "            data_transformation_dir=Path(config.data_transformation_dir)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Class\n",
    "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        logger.info(\"Feature Engineering started\")\n",
    "\n",
    "    def distance_numpy(self, df, lat1, lon1, lat2, lon2):\n",
    "        # Calculate distance based on latitude and longitude\n",
    "        p = np.pi / 180\n",
    "        a = 0.5 - np.cos((df[lat2] - df[lat1]) * p) / 2 + \\\n",
    "            np.cos(df[lat1] * p) * np.cos(df[lat2] * p) * \\\n",
    "            (1 - np.cos((df[lon2] - df[lon1]) * p)) / 2\n",
    "        return 12734 * np.arcsin(np.sqrt(a))\n",
    "\n",
    "    def transform_data(self, df):\n",
    "        df['distance'] = self.distance_numpy(\n",
    "            df, \n",
    "            'Restaurant_latitude', 'Restaurant_longitude',\n",
    "            'Delivery_location_latitude', 'Delivery_location_longitude'\n",
    "        )\n",
    "\n",
    "        columns_to_drop = ['Delivery_person_ID', 'Restaurant_latitude', 'Restaurant_longitude',\n",
    "                           'Delivery_location_latitude', 'Delivery_location_longitude',\n",
    "                           'Order_Date', 'Time_Orderd', 'Time_Order_picked']\n",
    "        df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "        logger.info(\"Dropped unnecessary columns\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame, y=None):\n",
    "        transformed_df = self.transform_data(X)\n",
    "        return transformed_df\n",
    "\n",
    "# Data Transformation Class\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_data_transformation_obj(self):\n",
    "        # Define the categories and pipelines for transformation\n",
    "        Road_traffic_density = ['Low', 'Medium', 'High', 'Jam']\n",
    "        Weather_conditions = ['Sunny', 'Cloudy', 'Fog', 'Sandstorms', 'Windy', 'Stormy']\n",
    "        categorical_columns = ['Type_of_order', 'Type_of_vehicle', 'Festival', 'City']\n",
    "        ordinal_encoder = ['Road_traffic_density', 'Weather_conditions']\n",
    "        numerical_column = ['Delivery_person_Age', 'Delivery_person_Ratings', \n",
    "                            'Vehicle_condition', 'multiple_deliveries', 'distance']\n",
    "\n",
    "        # Pipelines\n",
    "        numerical_pipeline = Pipeline([\n",
    "            ('impute', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        categorical_pipeline = Pipeline([\n",
    "            ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        ordinal_pipeline = Pipeline([\n",
    "            ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "            ('ordinal', OrdinalEncoder(categories=[Road_traffic_density, Weather_conditions])),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer([\n",
    "            ('numerical_pipeline', numerical_pipeline, numerical_column),\n",
    "            ('categorical_pipeline', categorical_pipeline, categorical_columns),\n",
    "            ('ordinal_pipeline', ordinal_pipeline, ordinal_encoder)\n",
    "        ])\n",
    "\n",
    "        logger.info(\"Pipeline steps completed\")\n",
    "        return preprocessor\n",
    "\n",
    "    def initiate_data_transformation(self, dataset: pd.DataFrame):\n",
    "        # Read train and test datasets\n",
    "        train_df = dataset.iloc[:len(dataset)//2]\n",
    "        test_df = dataset.iloc[len(dataset)//2:]\n",
    "        logger.info(\"Read train and test data\")\n",
    "\n",
    "        # Apply Feature Engineering\n",
    "        fe_obj = FeatureEngineering()\n",
    "        train_df = fe_obj.transform(train_df)\n",
    "        test_df = fe_obj.transform(test_df)\n",
    "\n",
    "        # Saving transformed data\n",
    "        transformed_train_path = self.config.data_transformation_train_dir\n",
    "        transformed_test_path = self.config.data_transformation_test_dir\n",
    "        train_df.to_csv(transformed_train_path, index=False)\n",
    "        test_df.to_csv(transformed_test_path, index=False)\n",
    "        logger.info(\"Saved transformed train and test data\")\n",
    "\n",
    "        # Apply Data Transformation\n",
    "        transformation_obj = self.get_data_transformation_obj()\n",
    "        target_column = \"Time_taken (min)\"\n",
    "        X_train = train_df.drop(columns=[target_column])\n",
    "        y_train = train_df[target_column]\n",
    "        X_test = test_df.drop(columns=[target_column])\n",
    "        y_test = test_df[target_column]\n",
    "\n",
    "        X_train_transformed = transformation_obj.fit_transform(X_train)\n",
    "        X_test_transformed = transformation_obj.transform(X_test)\n",
    "\n",
    "        # Save the transformation objects\n",
    "        save_obj(file_path=self.config.data_transformation_preprocessing_obj, obj=transformation_obj)\n",
    "        save_obj(file_path=self.config.data_transformation_dir / \"fe_obj.pkl\", obj=fe_obj)\n",
    "        logger.info(\"Saved transformation objects\")\n",
    "\n",
    "        # Return the transformed data and paths\n",
    "        return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-13 13:42:34,903:INFO:common:yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-01-13 13:42:34,905:INFO:common:yaml file: params.yaml loaded successfully]\n",
      "[2024-01-13 13:42:34,907:INFO:common:yaml file: schema.yaml loaded successfully]\n",
      "[2024-01-13 13:42:34,908:INFO:common:created directory at: artifacts]\n",
      "[2024-01-13 13:42:34,909:INFO:common:created directory at: artifacts\\data_transformation]\n",
      "[2024-01-13 13:42:34,910:INFO:common:created directory at: artifacts\\data_transformation\\transformation]\n",
      "[2024-01-13 13:42:34,985:INFO:2547875897:Dataset loaded for transformation]\n",
      "[2024-01-13 13:42:34,985:INFO:1195955226:Feature Engineering started]\n",
      "[2024-01-13 13:42:34,992:INFO:1195955226:Dropped unnecessary columns]\n",
      "[2024-01-13 13:42:34,992:INFO:2547875897:Feature engineering applied]\n",
      "[2024-01-13 13:42:34,994:INFO:1195955226:Read train and test data]\n",
      "[2024-01-13 13:42:34,994:INFO:1195955226:Feature Engineering started]\n",
      "[2024-01-13 13:42:34,996:ERROR:2547875897:Error in data transformation: 'Delivery_location_latitude']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Delivery_location_latitude'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\Foodtimepredictor\\foodtimepredictor\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Delivery_location_latitude'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     39\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in data transformation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[6], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature engineering applied\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Apply Data Transformation\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m train_df, test_df \u001b[38;5;241m=\u001b[39m \u001b[43mdata_transformation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_data_transformation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_transformed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData transformation applied\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Save the transformed data\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 85\u001b[0m, in \u001b[0;36mDataTransformation.initiate_data_transformation\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Apply Feature Engineering\u001b[39;00m\n\u001b[0;32m     84\u001b[0m fe_obj \u001b[38;5;241m=\u001b[39m FeatureEngineering()\n\u001b[1;32m---> 85\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mfe_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m test_df \u001b[38;5;241m=\u001b[39m fe_obj\u001b[38;5;241m.\u001b[39mtransform(test_df)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Saving transformed data\u001b[39;00m\n",
      "File \u001b[1;32md:\\Foodtimepredictor\\foodtimepredictor\\lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "Cell \u001b[1;32mIn[5], line 33\u001b[0m, in \u001b[0;36mFeatureEngineering.transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: pd\u001b[38;5;241m.\u001b[39mDataFrame, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 33\u001b[0m     transformed_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transformed_df\n",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m, in \u001b[0;36mFeatureEngineering.transform_data\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, df):\n\u001b[1;32m---> 15\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance_numpy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRestaurant_latitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRestaurant_longitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDelivery_location_latitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDelivery_location_longitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     columns_to_drop \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDelivery_person_ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRestaurant_latitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRestaurant_longitude\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDelivery_location_latitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDelivery_location_longitude\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     23\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrder_Date\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime_Orderd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime_Order_picked\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     24\u001b[0m     df\u001b[38;5;241m.\u001b[39mdrop(columns_to_drop, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m, in \u001b[0;36mFeatureEngineering.distance_numpy\u001b[1;34m(self, df, lat1, lon1, lat2, lon2)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistance_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m, df, lat1, lon1, lat2, lon2):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Calculate distance based on latitude and longitude\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m180\u001b[39m\n\u001b[1;32m----> 9\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mcos((\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlat2\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m df[lat1]) \u001b[38;5;241m*\u001b[39m p) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m     10\u001b[0m         np\u001b[38;5;241m.\u001b[39mcos(df[lat1] \u001b[38;5;241m*\u001b[39m p) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mcos(df[lat2] \u001b[38;5;241m*\u001b[39m p) \u001b[38;5;241m*\u001b[39m \\\n\u001b[0;32m     11\u001b[0m         (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mcos((df[lon2] \u001b[38;5;241m-\u001b[39m df[lon1]) \u001b[38;5;241m*\u001b[39m p)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m12734\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marcsin(np\u001b[38;5;241m.\u001b[39msqrt(a))\n",
      "File \u001b[1;32md:\\Foodtimepredictor\\foodtimepredictor\\lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\Foodtimepredictor\\foodtimepredictor\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Delivery_location_latitude'"
     ]
    }
   ],
   "source": [
    "# Main execution block\n",
    "try:\n",
    "    # Initialize configuration manager and load configuration\n",
    "    config_manager = ConfigurationManager()\n",
    "    data_transformation_config = config_manager.get_data_transformation_config()\n",
    "    \n",
    "    # Initialize DataTransformation class\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset_path = data_transformation_config.data_path\n",
    "    if not dataset_path.exists():\n",
    "        raise FileNotFoundError(f\"Dataset file not found at {dataset_path}\")\n",
    "\n",
    "    dataset = pd.read_csv(dataset_path)\n",
    "    logger.info(\"Dataset loaded for transformation\")\n",
    "\n",
    "    # Apply Feature Engineering\n",
    "    fe = FeatureEngineering()\n",
    "    dataset_transformed = fe.transform(dataset)\n",
    "    logger.info(\"Feature engineering applied\")\n",
    "\n",
    "    # Apply Data Transformation\n",
    "    train_df, test_df = data_transformation.initiate_data_transformation(dataset_transformed)\n",
    "    logger.info(\"Data transformation applied\")\n",
    "\n",
    "    # Save the transformed data\n",
    "    os.makedirs(data_transformation_config.data_transformation_dir, exist_ok=True)\n",
    "    train_df.to_csv(data_transformation_config.data_transformation_dir / \"transformed_train.csv\", index=False)\n",
    "    test_df.to_csv(data_transformation_config.data_transformation_dir / \"transformed_test.csv\", index=False)\n",
    "    logger.info(\"Transformed data saved\")\n",
    "\n",
    "    # Save the transformation objects (if necessary)\n",
    "    # ...\n",
    "    # Code for saving transformation objects\n",
    "    # ...\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in data transformation: {e}\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
